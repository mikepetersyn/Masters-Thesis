\documentclass[../../main.tex]{subfiles}
\begin{document}

\section{Experimental Setup}\label{sec:experimental_setup}

Section~\ref{subsec:implementation_details} presents details on the implementation of the application. This includes the conceptual realization of the architecture that is outlined in Section~\ref{sec:architecture_specification} and the technology solutions that were adopted.  Furthermore, internals of the data and communication flow between individual services of the application are explained. Finally, two aspects are discussed in more detail. For one thing, the technology for parallelization and thus scaling is covered. For another, the differentiated possibilities for data consistency will be highlighted. Section~\ref{subsec:methodologies} discusses the design of the experiments used to evaluate the advantages of the \gls{cids} compared to isolated \gls{ids}. The focus here is on testing the improvement of the detection performance under the assumption of the existence of local knowledge gaps and the reduction of the data volume to be exchanged.

\subsection{Implementation Details}\label{subsec:implementation_details}

A cloud-oriented architecture, consisting of four services for data processing (see Section~\ref{sec:architecture_specification}), is realized as a python streaming application \footnote{\url{https://gitlab.informatik.hs-fulda.de/verca/pattern-database}}. The data processing services, message queues and key-value stores are deployed using docker compose. Scalability, availability and resilience are achieved by deploying each service in a replicated fashion. Kafka is employed as the message queue that realizes the global and local event channels, that are responsible for distributing jobs among instances of the processing services. The global and local pattern databases are realized using Redis. As described in Section~\ref{sec:high_level_overview}, intrusion detection datasets are partitioned into regions and stored by using the respective regions as keys. In that way, data parallelization is achieved. In particular, data from each region in the key-value store can be processed independently. Hence, regions are also exploited as a job-distribution primitive. In other words, each processing service receives regions by listening on a specific topic of a Kafka message broker. As all instances of a service belong to a common consumer group, regions in a topic are distributed among the respective instances. Upon the reception of a region, a service starts its specific processing instructions on the data partition of the respective region by loading the data from the key-value store using the region as the key.

\begin{figure}[b!]
    \centering
    \includestandalone{2_mainmatter/5_experimental_evalution/tikz/implementation_details}
    \caption[Implementation Details]{Operation Principles of a Processing Service}  \label{fig:implementation}
 \end{figure}

As the processing services effectively manage the disseminatation of data between all members of the CIDS, the data consistency between infrastructures depends on the processing guarantees given by the employed message queue that distributes the jobs among the processing instances. Kafka provides a configuration that enables transactional communication, such that a strong consistency can be achieved. For example, upon the successfull execution of operations on a data partition, the messaging queue can be notified and the job is done. In contrast to that, upon a failure, the messaging service will try to distribute that job again. Typically, the decision for transactional guarantees comes with the cost of a higher delay. Furthermore, for data availability and consistency on a datastore-level, the consistency guarantees of the employed data store is relevant. Redis implements a master-replica scheme with asynchronous replication and this provides an eventual consistency.

\subsection{Methodologies}\label{subsec:methodologies}

The evaluation of the approach focuses on two main questions. Does the \gls{cids} improve the attack detection of local \gls{ids} in cases of local knowledge gaps and how much compression can be achieved and therefore reduce the communication overhead between local \gls{ids} in terms of data volume? In order to answer the question of attack detection improvement, extensive experiments evaluate the classification results of local \gls{ids} with and without the help of the \gls{cids}. The compression capabalities of the approach is determined by analyzing the data within the pattern databases. The experiments are conducted using different configuarion parameters for the hash size in order to reason about the partitioning effect of the Random Projection operation on the datasets and the resulting quality of the generative models.

The classification experiments are constructed to simulate the absence of knowledge within a local infrastructure. At first, the operating classifier that performs attack detection in that local infrastructure is not aware of specific attack information. However, by participating in the \gls{cids}, the local infrastructure is provided with attack information from other infrastructures that might fill its local knowledge gap. That local knowledge gap is constructed by removing a single attack class from the training dataset. As the testing dataset stays unaltered, the classifier is confronted with samples from an attack class that do not occur within its local training dataset. Systematically, in each iteration one attack class within the training dataset is removed and a classifier is fitted and evaluated. We refer to this type of evaluation as Skip-One-Class-Evaluation (SOCE). Logically, a single SOCE includes as many iterations, i.e. experiments, as there are attack classes in the local dataset of the evaluated infrastructure (see Table~\ref{tab:included_attack_classes}).

\begin{table}[H]
    \footnotesize
    \centering
    \setlength{\extrarowheight}{0pt}
    \addtolength{\extrarowheight}{\aboverulesep}
    \addtolength{\extrarowheight}{\belowrulesep}
    \setlength{\aboverulesep}{0pt}
    \setlength{\belowrulesep}{0pt}
    \setlength{\extrarowheight}{.1em}
    \input{table/included_attack_profiles.tex} 
    \caption[Attack Classes Included in the Datasets]{The table indicates wether a dataset includes a particular attack class (\cmark) or not (\xmark).}
    \label{tab:included_attack_classes}
\end{table}

The described classification experiments are conducted in two scenarios. The first one considers to create a synthetic dataset from the generative models within the pattern database and enhance the training dataset. The second scenario additionally includes the attack information provided by simple regions in the pattern database and therefore implies the help of the classification algorithm presented in Section X. In particular, flows from the testing dataset are hashed using the same Random Projection operation that is used for managing the Pattern Database. Then, the resulting hashes are compared to the hashes stored in the Pattern Database. If a hash represents a simple region, the contained label information is used as the classification result for the respective flow. And if the hash represents a complex region or is not available in the Pattern Database, the classifier that was fitted with the enhanced dataset is used for classification. 

Three different hash sizes (16-bit, 32-bit and 48-bit) are considered for all classification experiments. Additionally, two different baseline experiments are conducted for comparison. These two baseline experiments also involve the removal of single attack classes as described above. In the first experiment no data is shared between the infrastructures, which represents a scenario with isolated \glspl{ids} only. The second experiment considers to fill knowledge gaps with real data. That scenario refers to an alternative \gls{cids}, in which the training datasets are exchanged directly without any further. That means that the training dataset is merged with the original data from the training proportions of the other datasets. The obtained results represent the maximum performance that the presented \gls{cids} could theoretically achieve with the provided datasets. As there are three local infrastructures, two baseline scenarios and two scenarios for the presented architecture, each conducted with three different hash sizes, a number of 190 experiments are executed for the evaluation.

The same classification algorithm (Random Forest) and test size ($25\%$) is used for each experiment. Regarding the classification algorithm, the scikit-learn\footnote{Scikit-learn is a machine learning software library for the Python programming language.} implementation of the Random Forest Classification Algorithm \cite{breiman2001random} is used in the application and the experiments. The default hyperparameters of the library are used. The classification experiments are conducted as multiclass problem.

For the evaluation of the compression capability of the approach, we consider the number of flows that were assigned to each region and relate their size to the number of parameters that are written to the Global Pattern Database instead. In particular we know that each simple region is represented by a single label. Hence, each simple region contains a single parameter only. Furthermore, we know the number of parameters that are stored in complex regions from Section~\ref{sec:generative_fitting}, which depends on the number of unique labels in the respective region, the dimensionality of the data and the number of components of the respective \gls{gmm}. As the ratio of simple and complex regions and the results from the model selection (see Algorithm~\ref{alg:model_selection}) cannot be determined theoretically, these numbers have to be analyzed for each particular hash size and can only provide a trend and do not represent a general compression rate that is to be expected from any arbitrary dataset. 



\end{document}