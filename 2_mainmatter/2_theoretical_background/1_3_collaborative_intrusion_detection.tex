\subsection{Collaborative Intrusion Detection}

% was sind coordinated attacks

% typical characteristics of coordinated attacks

% typical attacks (scans, worms, dos, botnet)

% Wieso ein Kapitel über Coordinated Attacks im Zusammenhang mit Knowledge Sharing in CIDS? 
%   - Durch das Knowledge Sharing können insb. Informationen zu neuartigen Angriffen (z.B. Zero Days) mit anderen Mitgliedern im Verbund geteilt werden
%   - Coordinated Attacks sind häufig großflächig angelegt (large scale), sodass derselbe Angriff automatisiert auf eine große Menge von Systemen abzielt. Durch ein Teilen der Angriffsinformationen erzielt man folgende Vorteile:
%       o Teilen von vollständigen Angriffsinformationen für Datenbank: lokale Klassifizierer können neuen Angriff erkennen, da das Wissen in den Trainingsprozess integriert werden kann
%       o Teilen von Signaturen

survey on coordinated attacks in the context of collaborative intrusion detection systems\cite{Zhou2010}

However, when considering the development of the current threat environment, the effectiveness of conventional intrusion detection systems is limited. Technology trends, such as the internet of things or cloud computing, are main drivers for increasingly blurring corporate boundaries in the context of interconnection of infrastructures and shared resources. This transformation increases the potential attack surface of productive computer systems for large-scale and high-velocity cyber attacks, which traditional IDSs have limited effectiveness due to their isolated nature. For example, such stand-alone IDS will not be able to create connections between security events that occur at different infrastructures simultaneously. Due to the mentioned increase of attack surface that is related to the size of current computer networks, attackers may attempt to obfuscate the characteristic overall sequence of the intrusion by spreading single attack steps.

n order to address the aforementioned security problems of large IT systems, Collaborative Intrusion Detection Systems (CIDSs) have been proposed. In general, a CIDS is a network of several intrusion detection components that collect and exchange data on system security. A CIDS is essentially specified by two different types of components, namely the detection units and the correlation units, and their communication among each other. The detections units can be considered as conventional IDS that monitor a sub-network or a host and by that, generate low-level intrusion alerts. The correlation unit is responsible for merging the low-level intrusion alerts and their further post-processing. This includes, for instance, the correlation of the alerts, the generation of reports or the distribution of the information to the participants of the network. CIDSs pursue the following two goals \cite[24]{vasilomanolakis_collaborative_2016}.

\begin{itemize}
    \item The aggregation and correlation of data originating from different IDSs creates a holistic picture of the network to be monitored and enables the detection of distributed and coordinated attacks.
    \item CIDSs can monitor large-scale networks more effectively with the realization of a loadbalancing strategy. By sharing IDS resources across different infrastructures, short-term peak loads can be served, reducing the downtime of individual IDSs.
\end{itemize}

The requirements and key components are adopted from \cite{vas_2015}, who have summarized them within an survey. It should be noted that the structuring partly overlaps and that individual or several requirements influence each other. 

\subsubsection{Requirements}

\paragraph{Accuracy} Accuracy generally describes a collection of evaluation metrics for assessing the performance of the \acrshort{cids}. Frequently used metrics are, for example, the \acrfull{dr}, i.e. the ratio of correctly detected attacks to the total number of attacks, or the \acrfull{fpr}, which sets the number of normal data classified as an attack in relation to the total number of normal data. 

\paragraph{Minimal Overhead and Scalability} This requirement describes the operational overhead and the scalability of the system directly related to this. First, the algorithms and techniques for collecting, correlating, and aggregating data must require minimal computational overhead. Second, data distribution within the \acrshort{cids} must be as efficient. The performance required to operate the system should increase linearly with the resources used, so that computer systems of any size can be protected by the \acrshort{cids}. This property can be measured in theoretical terms by considering the complexity of the algorithms used. In practical terms, the passed time from the collection of a data point to the decision-making process can be measured.

\paragraph{Resilience} Resilience describes the ability of the system to be resistant to attacks, manipulations and system failures. A distinction is made between external attacks, such as DoS, and internal attacks by infiltrated \acrshort{cids} components. Moreover, it also covers fail-safety in general, which can be achieved, for example, by avoiding SPoFs.

\paragraph{Privacy} With regard to the protection and regulation of communication in the \acrshort{cids}, a distinction is made between internal and external communication. Data that is exchanged internally in the \acrshort{cids} network between members may contain potentially sensitive information that should not be disclosed directly to other participants for reasons of data privacy. 

This includes, among other things, legal aspects when it comes to sharing log and network data. In connection with the resilience of the system, securing communication against third parties using cryptographic methods also plays a role and represents a major challenge, especially in dynamically distributed architectures.

\paragraph{Self-configuration} This requirement describes the degree of automation of a system with regard to configuration and operation. Particularly in distributed and complex architectures, a high degree of automation is desired in order to avoid operating errors and enable automatic resolution of component failures. 

\paragraph{Interoperability} The individual components of the overall system, which were deployed in different system and network environments, should be able to interact with each other in the context of the \acrshort{cids}. In addition to system-wide standards for data collection, processing and exchange, there exists a trade-off between interoperability and privacy.

\subsubsection{Design Components}\label{ch:design_components}

\paragraph{Local Monitoring} \label{par:local_monitoring} First, a distinction is made between active and passive monitoring. Active monitoring refers to the use of honeypots that reveal themselves as attack targets in the infrastructure in order to collect attack data. Passive monitoring involves intrusion detection activity at the host or network level, which in turn can be divided into signature-based or anomaly-based methods according to the type of detection technique used (see Chapter \ref{ch:intrusion_detection_systems}). 

\paragraph{Membership Management}\label{par:membership_management} Membership management refers to ensuring secure communication channels in the form of an overlay network. Generally, membership management is categorized according to the organization and structure of the system topology. In terms of organization, there are either static approaches, in which members are added or removed manually, or dynamic approaches, in which components are organized automatically via a central entity or a protocol. Furthermore, the structure of the overlay network is relevant for the type of communication in the \acrshort{cids} network. This means that connections between the monitoring units are either centralized, hierarchical or distributed. 

\paragraph{Correlation and Aggregation}\label{par:correlation_and_aggregation} Before collected and analyzed data are shared with other participants in the \acrshort{cids} network, the data is correlated and similar data points are aggregated. The main purpose of generating global and synthetic alerts is firstly to reduce the amount of alerts overall and secondly to improve data insights. Correlation mechanisms can be categorized into single-monitor and monitor-to-monitor approaches. Single-monitor methods correlate data locally without sharing data with other monitor entities. Monitor-to-monitor approaches, on the other hand, share data with other monitoring units in order to correlate local data with shared data and thus enable insights that go beyond isolated methods. Further, a classification can be made according to the correlation techniques used, grouping four different approaches.
\begin{itemize}
    \item \textit{Similarity-based} approaches correlate data based on the similarity of one or more attributes. For instance, \cite{goo_2001} suggests using the 5-tuple information of the network data to detect duplicates within \acrshort{nids}s. The computation of similarity can be done in a variety of ways. For example, \cite{goo_2001b} defines a similarity function for each attribute and computes the overall data similarity by combining the functions using an expectation of similarity. High-dimensional data is usually problematic, as the difficulty for an effective calculation of similarity increases with the number of attributes \cite{zho_2009}.
    \item \textit{Attack scenario-based} approaches detect complex attacks based on databases that provide patterns for attack scenarios (e.g. \cite{hut_2004}, \cite{jaj_2002}). Such approaches have high accuracy for already known attacks. However, the accuracy decreases as soon as the patterns in the real data deviate from those in the database, since the definition of the scenario-rules are of a static quality in these approaches.
    \item \textit{Multistage alert correlation} aims to detect unknown multistage attacks by correlating defined pre- and post-conditions of individual alerts (e.g. \cite{cup_2002}, \cite{che_2003}). The idea behind the approach is based on the assumption that an attack is executed in preparation for a next step. The system states before and after an alert are modeled as pre- and postconditions, which are correlated with each other. While these approaches are more flexible than the all-static definition of attack scenarios, they still require the prior modeling of pre- and postconditions, which are based on expert knowledge.
    \item \textit{Filter-based} approaches filter irrelevant data in order to reduce the number of alerts within the intrusion detection context. For example, \cite{goo_2002} filters alerts by a ranking based on priorities of incidents. Priorities are calculated through comparing the target's known topology with the vulnerability requirements of the incident type. The rank that each alert is assigned to provides the probability for its validity. The accuracy of the filters is based on the quality of the description of the topology to be protected and require reconfiguration when changes are made to the infrastructure.
\end{itemize}

\paragraph{Data Dissemination}\label{par:data dissemniation} Data Dissemination describes the efficient distribution of correlated and aggregated data in the \acrshort{cids} network. How the data is disseminated is strongly influenced by the topology and membership management of the system. Centralized topologies have a predefined flow of information from the monitoring units to the central analysis unit. If the system is organized hierarchically, information flows statically or dynamically organized from lower monitoring units in the hierarchy to higher units. Distributed topologies allow the use of versatile strategies, such as flooding, selective flooding or publish-subscribe methods.

\paragraph{Global Monitoring}\label{par:global_monitoring} Global monitoring mechanisms are needed for the detection of distributed attacks which isolated \acrshort{ids}s cannot detect due to the limited information base. Thus, the detection of distributed attacks relies on the insight obtained by combining data from different infrastructures. This means that global monitoring is strongly dependent on the employed correlation and aggregation techniques. The overall strategy of the \acrshort{cids} is described by global monitoring and can have both generic and specific objectives. 

% requirements of CIDS

% design components

% verschiedene Architekturen mit Bild