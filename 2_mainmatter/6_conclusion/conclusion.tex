\documentclass[../../main.tex]{subfiles}
\begin{document}

\chapter{Conclusion and Outlook}\label{ch:conclusion}

This thesis contributes to the field of CIDS, in particular to the topic of data dissemination. It addresses the critical aspects of this topic by presenting a collaborative data sharing architecture that aims to fill knowledge gaps in local infrastructures by providing a global view on attack data. The effectiveness of the approach was investigated by implementing the specified architecture and evaluating it in a set of comprehensive experiments. This final chapter concludes the thesis and provides a summary of all contributions in Section~\ref{sec:conclusion}. In addition, an outlook on possible future work is presented in Section~\ref{sec:outlook}, which deepens specific questions or elaborates on the findings of the evaluation and proposes potential improvements.
\newpage

\section{Conclusion}\label{sec:conclusion}
This research aimed to design and develop a novel \gls{cids} architecture whose data dissemination component enables the exchange of information in the context of \gls{ml}-based attack detection, while respecting the critical challenges imposed on the collaboration. Based on the results of the experiments, it can be concluded that the proposed \gls{cids} not only provides advantages compared to isolated \glspl{ids}, but is also superior to an alternative scenario in which a naive approach involving a direct exchange of original is adopted. The findings also show that the three critical requirements, namely minimal overhead, data privacy, and interoperability, have been effectively addressed. In the following, the main contributions are summarized. The presented architecture addresses the challenges in the context of data dissemination primarily by using two mechanisms. First, information is shared via the exchange of generative models. To be precise, the parameters of GMMs are exchanged within the CIDS in order to create a global view of all attacks known in the CIDS. In this context, the basic idea of exchanging parameters of ML models is not a fundamental novelty. For example, in federated learning, updates to the parameters of distributed neural networks are collected and aggregated into a global model during the execution of the backpropagation algorithm. The aggregated update values are then propagated back to all participating neural networks, so that the information from the individual training datasets is combined and made available to each participant in the federation. In contrast to that, the generative data dissemination does not exchange the parameters of the GMMs during the training phase, but instead once the training is finished. However, the biggest distinguishing feature is the way in which the exchange is managed and, in combination with the described parameter exchange, represents the actual novelty that brings significant advantages. In fact, the compression of data by means of the transformation into generative models would not be scalable to realize without further measures. Thus, two advantages are created by partitioning the data using LSH, which is considered the second key mechanism. On the one hand, the processing of the data can be accelerated through parallelization without the risk of encountering racing conditions. In particular, workload peaks can be served dynamically in a cloud deployment. On the other hand, the continuous provision of new data is addressed by the fact that updates are only performed on individual partitions. This means that the occurence of new data does not require to reprocess the entire existing database, which is a significant advantage in general given the dynamic nature of the environment. In addition, the presented approach provides the possibility to differentiate between normal and attack data, since the training phase of the discriminative model is decoupled from the data exchange. This allows only attack data to be exchanged in the CIDS, which is then combined in the local infrastructures with the respective existing datasets, including the normal data. Preserving the anonymity of data through the use of synthetic data is a common advantage provided by generative ML models and used by the scientific community in many domains. However, the discussion of this issue needs to be done on two levels. First, it can be assumed that from a legal point of view, synthetic data is exempted from many constraints regarding its exploitation, since its origin is artificial. Second, it is also clear that as the performance of generative models progresses, it becomes increasingly difficult to tell the difference between synthetic and original data. The lack of ability to measure the leakage of sensitive information from the original data set into the synthetic data results in a gray area in this aspect. 

Regardless of this discussion, the reader has probably noticed that the data used for the evaluation does not contain any personal information or the like that needs to be protected. It should be added that the approach presented here can certainly be applied to data other than network flows. The usage of e.g. IP addresses as a feature in a classification problem usually leads to overfitting of the model, which is why such information has to be employed some other way. The provided prototype is designed as a cloud-native streaming application that follows multiple objectives. In the literature, centralized CIDS architectures are considered as neither scalable nor available. However, the distributed realization of the logically centralized architecture achieves exactly these properties, so that the implementation of a distributed P2P approach is not necessary and avoids the associated drawbacks. Splitting the application into different service units and the container-based deployment enables availability and dynamic scalability. The trade-off between low latency with regard to data distribution in the CIDS and a complete distribution of data to all relevant recipients depends on the settings of the employed messaging queue (Kafka) and key-value store (Redis). In the context of the evaluation, a new methodology, called SOCE, was introduced to test the effectiveness of data dissemination of a CIDS. The procedure assumes that isolated IDSs have knowledge gaps that are filled by participation in the CIDS. Knowledge gaps were simulated by systematically removing individual classes from the training data set. The respective test dataset, on the other hand, remains unchanged, so that a scenario is constructed wherein the IDS is contrasted with a novel attack. Different techniques for data dissemination can thus be directly compared in the context of detection performance. For data dissemination to work in the context of ml-based attack detection, a fundamental assumption is required. Whether subsets of training data, which originate from different datasets, i.e. infrastructures, can be mutually substituted in the context of a classification problem at all was examined in the context of the evaluation for the selected data. The results show a differentiated picture, so that it can be summarized that the degree of compatibility of the data varies considerably. However, it can be regarded as clearly positive that the exchange of information in the areas where no improvement was achieved also did not lead to a deterioration of the detection. Thus, data dissemination can be considered generally beneficial, although the degree of improvement is highly dependent on the data.  

\section{Outlook}\label{sec:outlook}

Based on the results, it is evident that a distinction between simple and complex regions does not offer any advantage, since the performance of the hybrid classification using a pattern detector yields worse results than the exclusive usage of synthetic data. For this reason, an improvement of the architecture could consist in providing synthetic data for each region, increasing the amount of data available and possibly further enhancing the detection performance. One aspect that has already been touched upon in the conclusion is the fact that the presented architecture could be evaluated by using other types of data, such as log data in the context of a HIDS, in order to make the advantage of data privacy more apparent. Finally, based on the experience gained during the design and implementation of the architecture, it is recommended that generative models that result from an automated process should be tested for quality, as can be seen in e.g. the Model Selection of the Generative Fitting Service, to prevent the introduction of noise into the decision base of an discriminator model.

\end{document}