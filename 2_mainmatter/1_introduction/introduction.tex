\documentclass[../../main.tex]{subfiles}
\begin{document}

\chapter{Introduction}

% In the context of Data Dissemination in CIDS and its associated challenges mentioned above,
% the thesis and its related objectives are presented in this section. First, the working thesis is
% presented and based on it the different key objectives and sub-objectives are derived. This is
% followed by the formulation of various research questions that serve as a thread for answering
% the thesis. Finally, it is described which target group this thesis addresses and what contribution
% the thesis provides to the scientific discourse on this topic.

\newpage
\section{Problem Description}

Many facets of modern society are based on information technology infrastructures, which exhibit an increasing degree of complexity and interconnection. Companies and institutions use IT systems to provide their services, enabling processes to be managed and handled both more effectively and more efficiently. As a consequence of this shift of processes onto IT systems, our society is becoming increasingly dependent on these systems. From these developments it can be derived that the protection of IT systems against malfunctions and espionage is of high importance. Thus, \glspl{ids} are a key asset in IT infrastructures to secure individual computer systems or networks. When securing computer networks, some form of IP packet analysis is often used to monitor network traffic based on packet header or payload data.
However, \gls{dpi} is very resource-intensive, making it difficult to monitor high-volume networks, especially those characterized by high dynamics where a forecast of the required resources is practically impossible \cite{dreger2004operational}. Another drawback of DPI solutions is that traffic from applications that encrypt their traffic end-to-end cannot be analyzed. A more scalable approach for network-based monitoring is to analyze network flows using flow exporters that collect and summarize packet header data and provide it as features for classification, for instance \cite{hofstede2018flow} . The topic of flow feature classification using \gls{ml} algorithms in the context of intrusion detection is popular in the research community  \cite{ahmad2021network}. However, the adoption rate of flow monitoring for detecting attacks on IT infrastructures is relatively low in practice due to fundamental challenges that \gls{ml}-based detection of attacks poses \cite{som_2010}. First, the costs incurred by errors in the model, especially false positives, are relatively high in this context. Furthermore, the results of many \gls{ml} algorithms are difficult to interpret, whereupon the transparency of detection suffers. Finally, collecting high quality data for training the models is a major challenge. Regardless of the question whether the fundamental challenges of \glspl{ids} based on flow data and machine learning can be solved sufficiently in the future, this work proceeds in that context and employs it as a use case for addressing challenges of another topic. In particular, when considering the development of the current threat environment, the effectiveness of conventional \glspl{ids} is limited. Technology trends, such as the internet of things or cloud computing, are main drivers for increasingly blurring corporate boundaries in the context of interconnection of infrastructures and shared resources. This transformation increases the potential attack surface of productive computer systems for large-scale and high-velocity cyber attacks, which traditional \glspl{ids} have limited effectiveness due to their isolated nature. Due to the mentioned increase of attack surface that is related to the size of current computer networks, attackers may attempt to obfuscate the characteristics of an intrusion by spreading single attack steps among multiple systems or networks. A common scenario would be scanning networks for opportunities to launch an intrusion, for example by exdecuting port scans. By slowing down the velocity of such techniques, attackers are able to evade current firewalls and IDSs \cite{riquet2012large}. Furthermore, it is common practice for attackers to perform automated attacks on a large number of different targets in order to speed up the identification of security vulnerabilities \cite{savage2005}. For this reason, it is reasonable to assume that identical or similar stealthy scans are performed on multiple infrastructures simultaneously. Isolated \gls{ids} will not be able to create connections between such security events that occur at different infrastructures. In order to address the aforementioned security problems, \gls{cids} have been proposed. A \gls{cids} refers to a network of multiple \glspl{ids} that exchange data with each other in order to increase detection performance, especially for distributed and novel attacks. In addition to an improved attack detection, another advantage is that \gls{cids} scale better than isolated \glspl{ids}, making them more suitable for monitoring large-scale networks. By sharing resources across different infrastructures, peak loads can be served using a loadbalancing strategy. Current literature divides the main functions of an IDS into different components \cite{vasilomanolakis_collaborative_2016}. Among these different components, the data dissemination is responsible for efficiently distributing the data that is collected and aggregated by the different \glspl{ids} in the network and thus avoiding unnecessary overhead in the \gls{cids}. In addition to the advantages a \gls{cids} provides, other challenges are introduced that need to be considered. In particular, the data dissemination is confronted with the following challenges. As already mentioned, the communication overhead is a central aspect that determines the efficiency of the \gls{cids} and thus the latency of information distribution among individual members. Furthermore, data privacy plays an important role, since sensitive data containing security-relevant information may not be shared without further ado. However, in order to enable the distribution of information, different techniques, for instance Bloom Filters \cite{Vasilomanolakis2015SkipMon} \cite{Locasto2005}, are employed. Finally, the dissemination must be performed in such a way that different IDSs can communicate with each other. Thus, a greater degree of interoperability requires fewer constraints and commitments on the part of local \gls{ids}.

\section{Contribution}

Current \glspl{cids} address the challenges related to data dissemination only in one particular niche aspect, as existing approaches generally focus on the distribution of simple alarm data. A communication beyond this, for example the exchange of specific attack patterns that could fill knowledge gaps in the context of \gls{ml}-based attack detection, is not feasible with the respective approaches. While ML-based attack detection offers many opportunities by providing powerful tools for identifying complex attack sequences, it still faces significant challenges, especially in the context of training data. For example, existing training data quickly becomes outdated and collecting new data is a complex task. Thus, as new malware and attack patterns emerge dynamically, effective mechanisms for sharing attack information must be found, such that different infrastructures can support each other and manage that process collectively. 

Hence, this work aims to enable the dissemination of training data among the members of a \gls{cids} while meeting the requirements imposed by the challenges in the context of data dissemination. For that, an innovative \gls{cids} architecture is developed and assessed in a novel evaluation procedure. Specifically, an efficient and privacy-friendly storage and dissemination solution called \textit{Pattern Database} is introduced. Attack data intended to be shared is used to train generative \gls{ml} models. Subsequently, the respective model parameters are disseminated in the \gls{cids}, such that attack information can be extracted in local infrastructures by creating synthetic data. By simulating knowledge gaps within local infrastructures, the Pattern Database is tested for its ability to fill the missing attack information using the synthetic data. In addition to that, a two-step detection process that employs the Pattern Database for classification is presented and evaluated for its detection performance.

This work is relevant to readers interested in intrusion detection, especially collaborative intrusion detection. However, anyone experiencing a similar use case, i.e., the efficient and anonymous sharing of structured data for subsequent use in \gls{ml} algorithms, will also benefit from this work. The following \glspl{rq} summarise the objectives and contributions of this work mentioned so far and add additional aspects to complement the research.

\begin{itemize}[leftmargin=6em]

    \item[RQ 1:] Can subsets of datasets from different infrastructures replace each other and provide equivalent information for a subsequent fiting of \gls{ml} models so that the same detection performance is achieved as with the original data? 
 
    \item[RQ 2:] How can a data dissemination component of a \gls{cids} be designed in order to meet the key requirements, namely minimal overhead, data privacy and interoperability.

    \item[RQ 3:] How does this approach address the typical trade-off between anonymity of data and usability of data in the context of privacy-aware data exchange?

    \item[RQ 4:] How can the effect of a CIDS on the detection performance of individual IDSs be measured on a general level.

  \end{itemize}

\section{Methodology}
In order to answer the above stated questions, a prototype application will be developed that realizes all concepts that aim to achieve the specified objectives. For this purpose, a detailed specification of the architecture and algorithms is provided first. For this purpose, a detailed specification of the architecture and algorithms is provided first. Subsequently, the application is evaluated by comprehensive experiments. The effectiveness of the data after inserting it into and retrieving it from the the Pattern Database for classification will be investigated and directly compared with the effectiveness of the original data that has not been subjected to any transformations. Furthermore, the compression properties of the system with respect to data persistence will be analyzed.

To be specific, network packet data from corresponding intrusion detection datasets for the evaluation of \gls{ids} are used to create datasets. For this purpose, three different datasets are selected, each of which is representative for the network traffic of a single infrastructure. A flow exporter is used to extract network flows from the packet data, which are then subject to further preprocessing steps, such as cleaning and labeling, using the information provided with the datasets.
Basically, the data are network packets that are generated and captured in test environments. Among them are benign traffic traces representing the usual behavior of users in productive computer networks and attack data traces that are created with commonly used tools for intruding into computer networks. The datasets have both differences and similarities regarding the contained attack classes, such that the basis for evaluating the exchange of attack information is balanced and results in a realistic collaboration scenario. The effectiveness of data dissemination is determined by the change in classification performance, measured by various metrics, that results from participation in the CIDS. Finally, while the aspects of data privacy and interoperability are explained by the description of the architecture, the aspect of minimal overhead is investigated by analysing the exchanged data volume.

\section{Thesis Outline}

The thesis consists of a total of 6 chapters and is mainly organized into a theoretical part (Chapter~\ref{ch:preliminaries} and \ref{ch:related_work}) and a practical part (Chapter~\ref{ch:generative_pattern_database} and \ref{ch:experimental_evaluation}). The theoretical part exclusively covers contents that can be sourced in the literature. In contrast, the practical part develops original contents, some of which are based on knowledge and concepts acquired in the theoretical part. A detailed overview of the thesis structure is given in the following.

\begin{description}
    \item[Chapter~\ref{ch:preliminaries}] First, the preliminaries chapter provides the reader with basic background information regarding the topics of Intrusion Detection, Locality Sensitive Hashing, Gaussian Mixtures and Principal Component Analysis. While the topic Intrusion Detection gives a general overview of the context of this work, the remaining topics are more specific and provide a detailed insight into techniques and algorithms that are used to realize the proposed \acrshort{cids} architecture.
    \item[Chapter~\ref{ch:related_work}] In this chapter, the current state of the art in three different areas related to this thesis is summarized and briefly discussed. First, techniques for data dissemination in \glspl{cids} are examined and the main challenges in this context are highlighted. Then, various established and novel approaches that use some form of similarity hashing in the context of intrusion detection are presented. Finally, the advantages of generative algorithms for intrusion detection are analyzed.
    \item[Chapter~\ref{ch:generative_pattern_database}] Based on the main challenges for data dissemination, this chapter develops a \gls{cids} architecture that realizes the principles of Generative Pattern Dissemination, introducing a novel approach in the field of intrusion detection. After a general introduction of the idea and functionality, a detailed specification of the architecture and the developed algorithms is given.
    \item[Chapter~\ref{ch:experimental_evaluation}] Furthermore, the proposed architecture is evaluated by conducting comprehensive experiments that simulate different scenarios. The evaluation focuses on two key features of the \gls{cids}. First, it is examined whether participating in the \gls{cids} improves the detection in each of the individual member infrastructures when local knowledge gaps exist. Then, the communication overhead of the architecture is analyzed. Both aspects are compared to a baseline scenario.
    \item[Chapter~\ref{ch:conclusion}] This chapter concludes the thesis by discussing the stated research questions and summarizing the contributions. Finally, several aspects from the evaluation will be addressed to discuss possible improvements to the architecture and to identify potential future work.
\end{description}

\end{document}