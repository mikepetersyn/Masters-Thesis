\documentclass[../../main.tex]{subfiles}
\begin{document}

\chapter{Related Work}
\newpage
\section{Data Dissemination in Collaborative Intrusion Detection}



% The key components for designing a CIDS architecture are described in \cite[p. 34]{vasilomanolakis_collaborative_2016}. Among them, data dissemination is particularly noteworthy as one of the fundamental components for the communication between members. A central aspect is the communication \textit{overhead} that is introduced with the dissemination of alerts and knowledge within a CIDS, which in turn is heavily influenced by the CIDS architecture \cite[p.39]{vasilomanolakis_collaborative_2016}, 



% The flow of information in centralized and hierarchical architectures is governed by the logical arrangement of components and their specific role. In centralized architectures, there is usually a central entity that controls communication. In hierarchical systems, the communication paths are mainly governed by the topological structure. In contrast to that, different techniques exist in distributed approaches. Whereas flooding refers to unfiltered data distribution to all members, selective techniques reduce the overhead by using, e.g., random walks \cite{Vishnumurthy2006}, gossipping approaches \cite{Dash2006}\cite{Ganesh2003} or publish-subscribe mechanisms. The latter provide flexible organization options and guarantee delivery. For example, subscriptions utilized in \cite{Janakiraman2003} are based on special attack forms.

% The data dissemination strategy of a CIDS not only defines the communication paths as described above, but also influences what kind of data is exchanged between the CIDS members while also specifying format and level of granularity. This also includes the central aspects of \textit{data privacy}, realized by utilization of, e.g., bloom filters \cite{Vasilomanolakis2015SkipMon}\cite{Locasto2005}, and \textit{interoperability} that can be obtained by standardized formats, such as the Intrusion Detection Message Exchange Format \cite{Cuppens2002}\cite{Duma2006}.

% In particular, there are two approaches to mention, that directly address the problems of communication overhead an privacy in this context. In \cite{Locasto2005}, the authors present an approach for the efficient and privacy aware distribution of alert data in a distributed CIDS. Before exchanging information, the respective data is compressed by the utilization of a bloom filter data structure. Upon an alert, the relevant information, e.g. IP address, is inserted ino the bloom filter. Since the bloom filter contains information on suspicious hosts, it is called \textit{watchlist}. The watchlist is shared among peers, which are selected by a network scheduling algorithm called \textit{whirlpool}, that dynamically creates an overlay that defines peer relationships.

% The authors state, that within data dissemination, there two challenges. First, the disclosure of sensitive data, e.g. IP addresses, to collaborative entities renders participation in the collaboration not an option. Second, the tradeoff between latency and accuracy of the information exchange and the required bandwidth. Centralized approaches disseminate information reliable and predictable, but they constitute a bottleneck. While distributed approaches scale well, information can be lost or delayed by partitioning the data among the peers.

% In the context of reducing communication overhead, this approach addresses this challenge twofold. First, alert data is compressed when inserted into the bloom filter by hashing. Second, only peers exchange data, which reduces overhead significantly, when compared to a complete distribution. However, bloom filters are probabilistic data structure, which exhibit increasing false positive matches with increasing filling degree. Thus, when scaling this approach, the probability that innocent hosts are considered as malicious, increases. 

% Also, the authors in \cite{Vasilomanolakis2015SkipMon} state, that a CIDS needs to provide \textit{scalability}, minimal message \textit{overhead}, \textit{privacy} of the exchanged alert data, an \textit{domain awareness}, which describes the ability to constrain alert disseminatation to specific sub-domains of a network. Instead of randomly creating sub-domains as in \cite{Locasto2005}, the authors suggest to incorporate network traffic similarities into account for this process. 

% data dissemination: extract specific features from alerts and add data into bloom filter; then utilize data disseminatation technique (e.g. flooding, partial flooding, gossipping) for sending bloom filters to other nodes (peers)

% similarity (alert) correlation: when nodes receive data from other nodes, they compute their similarity value by performing logical operations on the bloom filters

% similarity (alert) correlation: when nodes receive data from other nodes, they compute their similarity value by performing logical operations on the bloom filters, after calculating the similarity value, nodes will make use of a threshold value t to determine wheteher the similarity value is enough for joining a group (community creation)

% Community formation: After the successful dissemination and correlation of the alert data, each sensor creates a matrix with its local knowledge of other sensors. Based on this knowledge and along with the utilized threshold, sensors can identify others and form a community with them to, afterwards, exchange more fine-grained alert data.

% The problem of finding an optimal threshold value (golden standard) heavily depends on the network that is to be monitored.


% To sum up, the following challenges in the context of data dissemination are found to be critical for the success of the overall system. 
% \begin{description}

%     \item[Minimal Overhead] Detection latency can be affected by various factors, some of which are encountered in conventional IDS and others that are specifically relevant in the CIDS context. With regards to the data dissemination in CIDS, the computational overhead introduced by the communication of multiple monitors in the CIDS needs to be minimized, such that potential knowledge gains are available fast enough.

%     \item[Privacy] Members may not want to disclose data that contains information on system- and network states of their infrastructure, as it constitutes a privacy and security problem. This includes, among other things, legal aspects when it comes to sharing log and network data. Nonetheless, the exchange of this information is crucial for the effective operation of a CIDS.
    
%     \item[Interoperability] The individual components of the overall system, which were deployed in different system and network environments, should be able to interact with each other in the context of the CIDS. In addition to system-wide standards for data collection, processing and exchange, there exists a trade-off between interoperability and privacy.
    
%     \item[Domain Awareness] t.b.d. (a feature that increases scalability by reducing overhead and contributes to privacy by partially constraining communication; also increases accuracy, because only those alerts are shared that are relevant for w.r.t. to similarity of data etc.)

% \end{description}

\newpage
\section{Similarity Hashing in Malware Detection}


Searching for similar objects in large data sets is a fundamental challenge that has found important applications in many fields. An important subclass of similarity search is the nearest neighbour search problem, which becomes hard in the high dimensional case, when relying on exact algorithms like a linear scan ($O(n)$) as the best solution. However, many applications do not require an exact solution, such that in these cases a randomized algorithm can be used, which provides the correct solution with high probability in sublinear time \cite{datar_locality-sensitive_2004}. Therefore, approximate and randomized solution algorithms are widely used in practice. There is  popular approach known as locality-sensitive hashing (LSH) that allows searching in large databases for similar items in a randomized manner. This technique hashes similar input onto the same hash code with high probability for the purpose of populating a hash table. Since similar items are placed into the same buckets, this approach is suitable for data clustering or nearest neighbour search.


Also the field of cyber security has adopted methods suitable for similarity search, mainly for the analysis of polymorphic malware. This type of malware poses a significant challenge, since it changes its appearance over time in order to stay undetectable from antivirus software \cite[p.91]{whitman_principles_2018}. 
Traditional antivirus software uses cryptographic hash functions (SHA-256) to create file signatures. Such signatures are well suited to search for identical files in a knowledge database. However, due to the property of cryptographic diffusion, even minimal changes to the malware result in large differences in the resulting hash value. With the rapid evolution and proliferation of polymorphic malware, detection based on unique signatures no longer seems effective. 

Based on these developments, detection schemes based on approximate matching algorithms have initially become the focus of research. In contrast to LSH, approximate matching functions are designed for producing digests of objects and a subsequent comparison of such digests, which yields a confidence value reflecting the similarity of two objects \cite{moia_similarity_2017}. Popular approaches in this area are for example \textit{ssdeep}, which implements context triggered piecewise hashing (CTPH) \cite{kornblum_identifying_2006} or \textit{sdhash}, that makes use of bloom filters for the digest creation and comparison \cite{chow_data_2010}.


IDS with an Instance Selection base on LSH for Data Reduction \cite{baldini2021intrusion}; Instance selection identifies a subset of the original dataset whose application for the model training results in the same performance as if the entire dataset had been used;
improve accuracy by reducing noise in the dataset; reduction of computation resources required for training; the authors identify that the main issue for the applicability of instance selection algorithms in IDS is the computational complexity of the algorithms; By incorporating an algorithm called DR.LSH from \cite{aslani2020fast} that is based on LSH, redundant samples are defined as samples whose similarity to a given instance exceeds a preestblished threshold; by removing redundant samples, the volume of the dataset is decreased significantly while the detection performance has remained the same or is even improved for specific attack classes; however, neither the authors in \cite{baldini2021intrusion} nor those in \cite{aslani2020fast} describe the construction of the hash function used to assign a bucket index to a sample


\cite{opricsa2014locality} employ LSH for a fast clustering technique and apply it on a large collection of malware samples; motivated by the vast growth of malware samples, the authors are in favour for a fast algorithm for clustering malware into limited number of malware families, which are easier to manage than single samples; Although the algorithm is still quadratic in theory, the authors state that the coeffcient for the quadratic term is several orders of magnitude smaller and therefore significantly faster;
tested their algorithm on a collection of over one million malware samples; a further description of the dataset is not given; 

\cite{ludwig_friborg_malware_2019} malware classification using LSH and Neural Networks

\newpage
\section{Generative Algorithms and Intrusion Detection}

In the area of intrusion detection, generative algorithms primarily demonstrate their typical strengths, such that the ability to compensate for underrepresented classes with synthetic data generated by the generative model is by far the most frequent application. For example, the authors in \cite{8736331} present a network intrusion detection architecture in which a deep convolutional generative adversarial networks (DCGAN) is used to generate synthetic network intrusion data in order to balance the original training data. A multichannel SRU-based model is used as discriminative model for the classification task. The employed data for the experiments is versatile and includes the KDD99 dataset \cite{kdd99}, the NSL-KDD dataset \cite{nslkdd} and the CIC-IDS2017 dataset \cite{sharafaldin_toward_2018}. Evaluation results for both binary and multiclass classification show improvements regarding the employed metrics compared to the performance of common classification algorithms. However, the authors neglect to state parameter settings for the algorithms which were used for comparison and do not incorporate alternative upsampling algorithms in the experiments. In contrast to that, the authors in \cite{huang2020igan} compare their approach to common classification algorithms in combination with alternative balancing methods, namely random under-sampling, random over-sampling and SMOTE \cite{smote}. The presented architecture also employs a GAN for generating synthetic samples in the context of upsampling minority classes in the training data. Multiclass classification experiments were conducted using the NSL-KDD datset \cite{nslkdd}, the CIC-IDS2017 dataset \cite{sharafaldin_toward_2018} and the UNSW-NB15 dataset \cite{unswnb15}. Furthermore, the robustness of the approach is evaluated in detail by incrementally increasing the class imbalances in the experimental setup by random under-sampling. Although there is a slight downward trend in performance with increasing imbalance, the approach remains relatively stable. Another example is the architecture in \cite{lee2019ae}, where a feature extraction precedes the upsampling process by using an Autoencoder to transform statistical network flow features into a low-dimensional representation, which serve as input for the training of a CGAN. In all the stated approaches, the balancing of minority classes using generative algorithms leads to an increase in detection performance, compared to experiments without class balancing or with alternative balancing methods. However all these approaches do not incorporate an evaluation of the synthetic data before including them into the training data. The authors in \cite{shahriar2020g} present an interesting approach for evaluating synthetic data within their framework. There, the synthetic data is categorized into synthetic and pending data. Data flagged as synthetic is already verified and stays permanently in the datbase. The verification of the pending data depends on the decision of a controller module. Within the training phase, two classifier models are trained. The first model is trained on real and synthetic data and the second model is trained on real, synthetic and pending data. If the second model performs better than first model, the controller accepts the pending samples and flags them as synthetic. Otherwise the pending samples are rejected and removed from the database. Besides the utilization of generative algorithms for oversampling in intrusion detection, there are also other interesting applications. Some approaches employ GANs for synthesizing adversarial attack traffic that is used to evade an IDS, whose internal structure and parameters are unknown. For example, the authors in \cite{lin2022idsgan} state that the goal of the architecture is to generate malicious feature records similar to the attack traffic which can bypass the detection of the IDS. Then, following the synthetic records, attackers can derive actions on how to change their attacks in order to evade the respective IDS. From a technical perspective, in order to maintain specific functional features of attacks within the sample generation, specific attack attributes remain unaltered while nonfunctional features are fine-tuned in order to trick the classifier of the IDS. However, it has to ensured that an adversarial perturbation does not invalidate the features used for intrusion detection. This, the approach presented in \cite{usama2019generative} also includes a training mechanism for defense purposes that increases the robustness of the IDS against adversarials. Specifically, an adversarial training \cite{szegedy2013intriguing} is conducted, in which the detection model learns the possible adversarial perturbations by training on clean and adversarial examples. Another application derives from the field of distributed learning of deep neural networks. The authors in \cite{ferdowsi2019generative} leverage a distributed-learning architecture in order to share attack information among multiple IDS without the requirement of sharing real data samples. In particular, a GAN is trained by deploying multiple discriminators at different entities that act as the detection unit. The feedback of the discriminators within the training phase is aggregated to a central generator model that incrementally creates a global perspective without exchanging real data. It is shown that each participating discriminator performs well in the evaluation and the central generator represents a global collection of local datasets. However, while in the training phase, the generator has to send its synthetic data points to each of the participating discriminator models in the distributed system. Furthermore the appraoch is tested on a daily activity recognition dataset \cite{reyes2016transition}, which may be categorized into a health-related sensor-dataset but does not represent an intrusion detection dataset. Another drawback is the fact that in such an architecture, also the benign traffic of each local dataset is combined into the global knowledge which potentially introduces a significant amount of noise. 

\section{Main Distinguishing Features}
\end{document}