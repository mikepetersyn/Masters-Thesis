\subsection{Network Flow Monitoring}\label{subsec:network_flow_monitoring}

Network monitoring is a key component for network management as network administrator derive decisions based on data that results from monitoring activities. By collecting data from network devices, such as switches, routers or clients, the current behaviour of the network is measured. Commonly, this behaviour has to meet some minimum application requirements, which can be summarized by the term Quality of Service (QoS) \cite[406]{tanenbaum2021computer}. In this context, the most early and vague definition of a network flow was introduced as "a sequence of packets traveling from the source to the destination" \cite{clark1988design}. Here, no further characteristics of a flow are given and it is not clear how one flow is differentiated from another flow. Later in the 1990s, however, the demand arose for a finer-grained view of network traffic than that provided by interface-level counters, but without the disadvantage of the huge amounts of data generated by packet tracking. Evidently, the concept of network flows has filled this gap in demand and has gained a central role in network management and research today \cite{trammell2011introduction}.

Since the first attempts at standardization in the 1990s through the efforts of the Internet Enginnering Task Force (IETF), a number of proprietary standards have emerged as each network device vendor has implemented its own flow export protocol. In order to improve interoperability in the area of network flow measurement, the IETF established the IP Flow Information Export (IPFIX) working group. This working group defined the IPFIX standard (RFC 5101), which defines the term network flow as follows.

A network flow is an aggregation of all network packets that pass an observation point of a network during a certain time interval and share a set of common properties. These properties are defined as the result of applying a function to the value of
\begin{enumerate}
    \item one or more packet, transport or application header fields,
    \item one ore more characteristics of the packet itself,
    \item one or more fields derived from packet treatment.
\end{enumerate}

This definition is loose enough to cover the range from a flow containing all packets observed at a network interface to a flow that consists only of a single packet between two applications. Note, that this definition of the set of properties is also less strict than the conventional definition of the five-tuple consisting of source IP address, source port, destination IP address, destination port and protocol \cite{rfc5101}

In general, network flows can appear either as unidirectional flow, which aggregates all packets from host A to host B (or vice versa), or as bidirectional format, that aggregates all packets regardless of direction. Depending on which flow format and flow exporter is used, additional information, e.g. statistical calculations on bytes per second, can be obtained. Other common network flow protocols are NetFlow \cite{rfc3954}, OpenFlow \cite{mck_2008} and sFlow \cite{pha_2004}.

\begin{figure}[t]
    \centering
    \includestandalone{2_mainmatter/2_preliminaries/1_intrusion_detection/tikz/flow_export}
    \caption{test}
    \label{fig:flow-export}
\end{figure}


Systems that generate flow data and extract additional information are called flow exporters. Generally, flow exporters are part of a general flow monitoring architecture \cite{hof_2014}, that consists of four different processes (see Figure \ref{fig:flow-export}). The \textit{packet observation} is done on interfaces of packet forwarding devices by capturing network packets and executing specific preprocessing steps like timestamping and truncation. The process of \textit{flow metering} describes the aggregation of packets into flow records. There, a set of functions, including packet header capturing, timestamping, sampling and classifying is applied on values of the packet stream listed above. Furthermore, flow records are  maintained, which may include creating, deleting or udpating records, or computing statistical flow features. After that, Fthe \textit{exporting process} places flow records in a datagram of the deployed export protocol and sends them to one or more collecting processes. Finally, the \textit{collection process} is responsible for the reception, storage and preprocessing of flow records, produced by the preceding step. Typically, the collected data is analyzed. This can be done, for example, in the context of \gls{ids} or traffic profiling.

Using network flows for intrusion detection has several advantages over \gls{dpi}. For example, \gls{dpi} requires highly complex and expensive infrastructure for storage and analysis of the data \cite{hof_2014}. Since flow exporter setups rely on packet header fields and statistical aggregations, a significant data reduction is achieved, which is why an analysis of network flows is scalable and also applicable for high-speed networks \cite{hof_2014}. In addition, discarding the payload results in a better compliance with data retention laws and privacy policies.